//
//  ContentView.swift
//  Free Photo CleanUp APP
//
//  Created by chang chiawei on 2025-07-28.
//

//  ContentView.swift
//  Free Photo CleanUp APP

import SwiftUI
import SwiftData
import Photos

enum PhotoCategory: String, CaseIterable, Identifiable {
    case selfie = "è‡ªæ‹"
    case live = "åŸæ³ç…§ç‰‡"
    case portrait = "äººåƒ"
    case timelapse = "ç¸®æ™‚æ”å½±"
    case slow = "æ…¢å‹•ä½œ"
    case burst = "é€£æ‹"
    case screenshot = "æˆªåœ–"
    case screenRecording = "è¢å¹•éŒ„å½±"

    var id: String { rawValue }
}

struct ContentView: View {
    @Environment(\.modelContext) private var modelContext
    @Query private var items: [Item]

    @State private var images: [UIImage] = []
    @State private var similarPairs: [(Int, Int)] = []
    @State private var showResults = false
    @State private var isProcessing = false
    @State private var showAlert = false
    @State private var selectedCategory: PhotoCategory = .selfie

    var body: some View {
        NavigationView {
            VStack {
                Picker("åˆ†é¡", selection: $selectedCategory) {
                    ForEach(PhotoCategory.allCases) { cat in
                        Text(cat.rawValue).tag(cat)
                    }
                }
                .pickerStyle(.segmented)
                .padding()
                
                Button("è¼‰å…¥åˆ†é¡åœ–ç‰‡") {
                    fetchAssets(for: selectedCategory) { assets in
                        loadImages(from: assets)
                    }
                }
                
                ScrollView {
                    LazyVGrid(columns: Array(repeating: .init(.flexible()), count: 3)) {
                        ForEach(images.indices, id: \.self) { idx in
                            Image(uiImage: images[idx])
                                .resizable()
                                .scaledToFill()
                                .frame(width: 100, height: 100)
                                .clipped()
                        }
                    }.padding()
                }
                
                if isProcessing {
                    ProgressView("Analyzing photos...")
                } else {
                    Button("Start Similarity Check") {
                        isProcessing = true
                        fetchFirst100Images { fetchedImages in
                            print("âœ… å·²è¼‰å…¥åœ–ç‰‡æ•¸é‡ï¼š\(fetchedImages.count)")
                            
                            if fetchedImages.isEmpty {
                                isProcessing = false
                                showAlert = true
                                return
                            }
                            images = fetchedImages
                            processImages()
                        }
                    }
                }
                
                if showResults {
                    NavigationLink("Show Similar Images", destination: SimilarImagesView(similarPairs: similarPairs, images: images))
                }
            }
            .navigationTitle("Free Photo CleanUp")
            .padding()
            .alert("æœªæ‰¾åˆ°ä»»ä½•åœ–ç‰‡ï¼Œè«‹ç¢ºèªæ‚¨çš„ç›¸ç°¿æœ‰ç…§ç‰‡ä¸¦å…è¨±å–ç”¨æ¬Šé™ã€‚", isPresented: $showAlert) {
                Button("OK", role: .cancel) { }
            }
        }
    }

    func fetchAssets(for category: PhotoCategory, completion: @escaping ([PHAsset]) -> Void) {
        let options = PHFetchOptions()
        options.sortDescriptors = [NSSortDescriptor(key: "creationDate", ascending: false)]
        
        switch category {
        case .selfie:
            let collection = PHAssetCollection.fetchAssetCollections(
                with: .smartAlbum,
                subtype: .smartAlbumSelfPortraits,
                options: nil)
            var arr: [PHAsset] = []
            collection.enumerateObjects { col, _, _ in
                let assets = PHAsset.fetchAssets(in: col, options: options)
                assets.enumerateObjects { asset, _, _ in arr.append(asset) }
            }
            completion(arr)
            
        case .burst:
            options.predicate = NSPredicate(format: "representsBurst == YES")
            fallthrough
            
        case .live, .portrait, .timelapse, .slow, .screenshot, .screenRecording:
            // åŸæœ‰ bitmask predicate æ–¹æ³•
            var mask: UInt = 0
            switch category {
            case .live:
                mask = PHAssetMediaSubtype.photoLive.rawValue
            case .portrait:
                mask = PHAssetMediaSubtype.photoDepthEffect.rawValue
            case .timelapse:
                mask = PHAssetMediaSubtype.videoTimelapse.rawValue
            case .slow:
                mask = PHAssetMediaSubtype.videoHighFrameRate.rawValue
            case .screenshot:
                mask = PHAssetMediaSubtype.photoScreenshot.rawValue
            case .screenRecording:
                mask = 524288
            default:
                break
            }
            if mask > 0 {
                options.predicate = NSPredicate(format: "mediaSubtypes & %d != 0", Int(mask))
            }
            let mediaType: PHAssetMediaType =
            (category == .timelapse || category == .slow || category == .screenRecording) ? .video : .image
            let fetchResult = PHAsset.fetchAssets(with: mediaType, options: options)
            var arr: [PHAsset] = []
            fetchResult.enumerateObjects { asset, _, _ in arr.append(asset) }
            completion(arr)
        }
    }


    func loadImages(from assets: [PHAsset]) {
        images.removeAll()
        let manager = PHImageManager.default()
        let reqOpts = PHImageRequestOptions()
        reqOpts.isSynchronous = false
        reqOpts.deliveryMode = .highQualityFormat
        
        for asset in assets {
            manager.requestImage(for: asset, targetSize: CGSize(width: 200, height: 200),
                                 contentMode: .aspectFill, options: reqOpts) { img, _ in
                if let img {
                    DispatchQueue.main.async { images.append(img) }
                }
            }
        }
    }

    private func addItem() {
        withAnimation {
            let newItem = Item(timestamp: Date())
            modelContext.insert(newItem)
        }
    }

    private func deleteItems(offsets: IndexSet) {
        withAnimation {
            for index in offsets {
                modelContext.delete(items[index])
            }
        }
    }

    func processImages() {
        var embeddings: [[Float]] = Array(repeating: [], count: images.count)
        let group = DispatchGroup()

        for (index, img) in images.enumerated() {
            print("ğŸ”„ é–‹å§‹è™•ç†ç¬¬ \(index + 1) å¼µåœ–")

            group.enter()
            extractEmbedding(from: img) { vector in
                if let v = vector {
                    embeddings[index] = v
                } else {
                    print("âŒ ç¬¬ \(index + 1) å¼µåœ–ç‰‡å‘é‡æå–å¤±æ•—")
                }
                group.leave()
            }
        }

        group.notify(queue: .main) {
            print("ğŸ“¦ å‘é‡æ¨£æœ¬ï¼š\(embeddings.first ?? [])")
            print("ğŸ§  ç›¸ä¼¼åº¦è¨ˆç®—é–‹å§‹")

            similarPairs = findSimilarPairs(embeddings: embeddings, threshold: 0.97)

            print("ğŸ“¸ æ‰¾åˆ°ç›¸ä¼¼åœ–ç‰‡çµ„åˆæ•¸ï¼š\(similarPairs.count)")
            for pair in similarPairs {
                print("ğŸ”— \(pair.0) èˆ‡ \(pair.1) æ˜¯ç›¸ä¼¼åœ–ç‰‡")
            }

            showResults = true
            isProcessing = false
        }
    }
}

#Preview {
    ContentView()
        .modelContainer(for: Item.self, inMemory: true)
}
